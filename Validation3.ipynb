{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPc+9s1uL3UnDk4P773KgVH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KOJdKSqSO1RW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748104852469,"user_tz":-540,"elapsed":16407,"user":{"displayName":"ê°•í™”ê²½","userId":"05664098802888959715"}},"outputId":"05b493cf-c738-415c-9e21-16b062088f62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install nptdms"],"metadata":{"id":"OJy6D2NDO7yX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748104973993,"user_tz":-540,"elapsed":10471,"user":{"displayName":"ê°•í™”ê²½","userId":"05664098802888959715"}},"outputId":"019fd0b9-d13d-4e74-d5b2-feccf005ca10"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nptdms\n","  Downloading nptdms-1.10.0.tar.gz (181 kB)\n","\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/181.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m153.6/181.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from nptdms) (2.0.2)\n","Building wheels for collected packages: nptdms\n","  Building wheel for nptdms (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nptdms: filename=nptdms-1.10.0-py3-none-any.whl size=108456 sha256=7225cab5b06df343f1b68f8fc0e04c35735db8149a65481adb3424cf3e37becd\n","  Stored in directory: /root/.cache/pip/wheels/1b/4b/17/21e8b03b37ea51ce7ec9f5570cdf0decca93f537d61c06880f\n","Successfully built nptdms\n","Installing collected packages: nptdms\n","Successfully installed nptdms-1.10.0\n"]}]},{"cell_type":"markdown","source":["ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"],"metadata":{"id":"R5qyhjRbPDi1"}},{"cell_type":"code","source":["import numpy as np\n","import os\n","import pandas as pd\n","from scipy.fft import rfft\n","import pywt\n","from nptdms import TdmsFile\n","import joblib\n","from tensorflow.keras.models import load_model"],"metadata":{"id":"8nLbzBVZLlkP","executionInfo":{"status":"ok","timestamp":1748105243837,"user_tz":-540,"elapsed":9,"user":{"displayName":"ê°•í™”ê²½","userId":"05664098802888959715"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def load_tdms_file(file_path):\n","    tdms_file = TdmsFile.read(file_path)\n","\n","    group_name_vibration = tdms_file.groups()[0].name\n","    group_name_operation = tdms_file.groups()[1].name\n","\n","    vib_channels = tdms_file[group_name_vibration].channels()\n","    vib_data = {ch.name.strip(): ch.data for ch in vib_channels}\n","\n","    operation_channels = tdms_file[group_name_operation].channels()\n","    operation_data = {ch.name.strip(): ch.data for ch in operation_channels}\n","\n","    return vib_data, operation_data"],"metadata":{"id":"wYLbB5McE-_k","executionInfo":{"status":"ok","timestamp":1748105082178,"user_tz":-540,"elapsed":22,"user":{"displayName":"ê°•í™”ê²½","userId":"05664098802888959715"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë¶„í•  (window_size ìƒ˜í”Œ, overlap ë¹„ìœ¨)\n","def sliding_window(data, window_size=25600, overlap=0.5):\n","    step = int(window_size * (1 - overlap))\n","    return np.array([\n","        data[start:start + window_size]\n","        for start in range(0, len(data) - window_size + 1, step)\n","    ])  # (ìœˆë„ìš° ìˆ˜, window_size, ì±„ë„ ìˆ˜)\n","\n","# 1ì°¨ì› ì‹ í˜¸ì— ëŒ€í•´ WPT+FFT top_k ì—ë„ˆì§€ íŠ¹ì§• ì¶”ì¶œ\n","def extract_wpt_fft_features(signal, wavelet='db4', level=3, top_k=10):\n","    wp = pywt.WaveletPacket(data=signal, wavelet=wavelet, mode='symmetric', maxlevel=level)\n","    nodes = [node.path for node in wp.get_level(level, 'freq')]\n","    features = []\n","    for node in nodes:\n","        coeffs = wp[node].data\n","        fft_vals = np.abs(rfft(coeffs))\n","        top_features = np.sort(fft_vals)[-top_k:]\n","        features.extend(top_features)\n","    return np.array(features)  # (ë…¸ë“œ ìˆ˜ Ã— top_k, )\n","\n","# TDMS íŒŒì¼ ê²½ë¡œë¡œë¶€í„° ì§„ë™ ë°ì´í„° ì½ì–´, ìœˆë„ìš°ë³„ WPT+FFT íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜\n","def extract_vibration_array_with_features(file_path, window_size=25600, overlap=0.5, wavelet='db4', level=3, top_k=10):\n","    vib_data, _ = load_tdms_file(file_path)\n","    channels = [\"CH1\", \"CH2\", \"CH3\", \"CH4\"]\n","    vib_arrays = [vib_data[ch] for ch in channels if ch in vib_data]\n","    vib_matrix = np.vstack(vib_arrays).T  # (ìƒ˜í”Œ ìˆ˜, 4)\n","\n","    windows = sliding_window(vib_matrix, window_size=window_size, overlap=overlap)  # (ìœˆë„ìš° ìˆ˜, window_size, 4)\n","\n","    all_features = []\n","    for window in windows:\n","        window_features = []\n","        for ch_idx in range(window.shape[1]):\n","            signal = window[:, ch_idx]\n","            feat = extract_wpt_fft_features(signal, wavelet=wavelet, level=level, top_k=top_k)\n","            window_features.extend(feat)\n","        all_features.append(window_features)\n","\n","    return np.array(all_features)  # (ìœˆë„ìš° ìˆ˜, ì±„ë„ ìˆ˜ * íŠ¹ì§• ìˆ˜)\n","\n","def process_all_train_folders(base_path, folder_names):\n","    all_feature_rows = []\n","\n","    for folder_name in folder_names:\n","        folder_path = os.path.join(base_path, folder_name)\n","        tdms_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.tdms')])\n","\n","        for tdms_file in tdms_files:\n","            file_path = os.path.join(folder_path, tdms_file)\n","            features = extract_vibration_array_with_features(file_path)\n","\n","            for i, feature in enumerate(features):\n","                all_feature_rows.append({\n","                    'file_name': tdms_file,\n","                    'window_index': i,\n","                    'features': feature,\n","                    'folder': folder_name\n","                })\n","\n","    return pd.DataFrame(all_feature_rows)\n","\n","\n","# --- ì„¤ì •ê°’ ---\n","base_path = \"/content/drive/MyDrive/KSPHM-data-challenge/Validation Set\"\n","folder_names = [f\"Validation{i}\" for i in range(1, 7)]  # Train1 ~ Train8\n","\n","# --- íŠ¹ì§• ì¶”ì¶œ ìˆ˜í–‰ ---\n","features_df = process_all_train_folders(base_path, folder_names)\n","\n","features_df['file_name'] = features_df['file_name'].str.replace(r'\\.tdms$', '', regex=True)\n","\n","print(f\"ì´ ìœˆë„ìš° ìˆ˜: {len(features_df)}\")\n","print(type(features_df['features'].iloc[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6xouoR5FA9O","executionInfo":{"status":"ok","timestamp":1748105243830,"user_tz":-540,"elapsed":160317,"user":{"displayName":"ê°•í™”ê²½","userId":"05664098802888959715"}},"outputId":"95fc8ff3-a0b8-412f-aace-73383cb74c81"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["ì´ ìœˆë„ìš° ìˆ˜: 5947\n","<class 'numpy.ndarray'>\n"]}]},{"cell_type":"markdown","source":["ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡ ìˆ˜í–‰ í›„ í‰ê°€ ì ìˆ˜ ì¶œë ¥"],"metadata":{"id":"ePcwRb9IH1BA"}},{"cell_type":"code","source":["# ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ\n","model_path = \"/content/drive/MyDrive/KSPHM-data-challenge/model/simple_cnn_lstm_model.h5\"\n","model = load_model(model_path, compile=False)\n","print(\"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ:\", model_path)\n","\n","# Validation ë°ì´í„°ì…‹ í´ë” ê²½ë¡œ\n","validation_base_path = \"/content/drive/MyDrive/KSPHM-data-challenge/Validation Set\"\n","validation_folders = [f\"Validation{i}\" for i in range(1, 7)]\n","\n","# Scaler ë¡œë“œ\n","X_scaler = joblib.load(\"/content/drive/MyDrive/KSPHM-data-challenge/scalers/X_scaler.pkl\")\n","y_scaler = joblib.load(\"/content/drive/MyDrive/KSPHM-data-challenge/scalers/y_scaler.pkl\")\n","\n","# Validation íŠ¹ì§• ì¶”ì¶œ\n","X_val = np.stack(features_df['features'].values)  # (samples, features)\n","X_val = X_val[..., np.newaxis]\n","\n","# Trainì—ì„œ ì‚¬ìš©í–ˆë˜ ìŠ¤ì¼€ì¼ëŸ¬ ì‚¬ìš©\n","samples_val, feat_dim, channels = X_val.shape\n","X_val_reshaped = X_val.reshape(samples_val, feat_dim * channels)  # (samples, feat_dim)\n","\n","X_val_scaled = X_scaler.transform(X_val_reshaped)  # Trainì—ì„œ fitëœ scalerë¡œ transformë§Œ\n","\n","# ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ reshape\n","X_val_final = X_val_scaled.reshape(samples_val, feat_dim, channels)\n","\n","# ëª¨ë¸ ì˜ˆì¸¡\n","y_val_pred_scaled = model.predict(X_val_final, verbose=1)\n","\n","# ì—­ìŠ¤ì¼€ì¼ë§\n","y_val_pred = y_scaler.inverse_transform(y_val_pred_scaled)\n","\n","# ê²°ê³¼ ì €ì¥\n","features_df['RUL_pred_sec'] = y_val_pred.flatten()\n","\n","# í™•ì¸\n","print(features_df[['file_name', 'window_index', 'RUL_pred_sec']].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zAcRwLFkIf0s","executionInfo":{"status":"ok","timestamp":1748106600837,"user_tz":-540,"elapsed":4139,"user":{"displayName":"ê°•í™”ê²½","userId":"05664098802888959715"}},"outputId":"ffd40a07-9faa-4551-cb6b-7498024617e1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: /content/drive/MyDrive/KSPHM-data-challenge/model/simple_cnn_lstm_model.h5\n","\u001b[1m186/186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step\n","                                           file_name  window_index  \\\n","0  modified_KIMM Simulator_KIMM Bearing Test_2016...             0   \n","1  modified_KIMM Simulator_KIMM Bearing Test_2016...             1   \n","2  modified_KIMM Simulator_KIMM Bearing Test_2016...             2   \n","3  modified_KIMM Simulator_KIMM Bearing Test_2016...             3   \n","4  modified_KIMM Simulator_KIMM Bearing Test_2016...             4   \n","\n","   RUL_pred_sec  \n","0  11948.326172  \n","1  10991.068359  \n","2  11946.134766  \n","3  12097.870117  \n","4  13621.589844  \n"]}]},{"cell_type":"code","source":["# ê° Validation í´ë”ë³„ ë§ˆì§€ë§‰ ìœˆë„ìš°ì˜ ì˜ˆì¸¡ RUL ì„ íƒ\n","final_rul_scores = (\n","    features_df.groupby('folder')\n","    .apply(lambda df: df.sort_values('window_index').iloc[-1])  # ë§ˆì§€ë§‰ ìœˆë„ìš°\n","    .reset_index(drop=True)\n",")\n","\n","# ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ì»¬ëŸ¼ êµ¬ì„±\n","result_df = pd.DataFrame({\n","    'File': final_rul_scores['folder'],\n","    'RUL_Score(sec)': final_rul_scores['RUL_pred_sec']\n","})\n","\n","# ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥\n","output_path = \"/content/drive/MyDrive/KSPHM-data-challenge/RUL_Score/rul_scores1.xlsx\"\n","result_df.to_excel(output_path, index=False)\n","\n","print(\"ì—‘ì…€ ì €ì¥ ì™„ë£Œ:\", output_path)\n","print(result_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gb24KfBLLS2","executionInfo":{"status":"ok","timestamp":1748106648724,"user_tz":-540,"elapsed":602,"user":{"displayName":"ê°•í™”ê²½","userId":"05664098802888959715"}},"outputId":"0404f23f-a051-4f97-93bf-15b4c29233d9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-a304f7d28d4b>:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda df: df.sort_values('window_index').iloc[-1])  # ë§ˆì§€ë§‰ ìœˆë„ìš°\n"]},{"output_type":"stream","name":"stdout","text":["ì—‘ì…€ ì €ì¥ ì™„ë£Œ: /content/drive/MyDrive/KSPHM-data-challenge/RUL_Score/rul_scores1.xlsx\n","          File  RUL_Score(sec)\n","0  Validation1    12023.895508\n","1  Validation2    71448.632812\n","2  Validation3    48502.957031\n","3  Validation4    73356.601562\n","4  Validation5    74936.945312\n","5  Validation6    29772.058594\n"]}]},{"cell_type":"markdown","source":["í‰ê°€ íŒŒì´í”„ë¼ì¸"],"metadata":{"id":"NfwntXZ-R4TP"}},{"cell_type":"code","source":["# ì˜¤ì°¨ ê³„ì‚°\n","def calculate_error(ActRUL, PredRUL):\n","    error = 100 * (ActRUL - PredRUL) / ActRUL\n","    return error\n","\n","# ì •í™•ë„ ì ìˆ˜ ê³„ì‚°\n","def calculate_accuracy_score(error):\n","    ln_0_5 = np.log(0.5)\n","    score = np.where(\n","        error <= 0,\n","        np.exp(-ln_0_5 * error / 20),\n","        np.exp(+ln_0_5 * error / 20)\n","    )\n","    return score\n","\n","# ìµœì¢… ì ìˆ˜ ê³„ì‚°\n","def calculate_final_score(accuracy_scores):\n","    return np.mean(accuracy_scores)\n","\n","# ì „ì²´ í‰ê°€ íŒŒì´í”„ë¼ì¸\n","def evaluate_rul_prediction(ActRUL, PredRUL):\n","    error = calculate_error(ActRUL, PredRUL)\n","    accuracy_scores = calculate_accuracy_score(error)\n","    final_score = calculate_final_score(accuracy_scores)\n","    return {\n","        \"Error\": error,\n","        \"Accuracy_scores\": accuracy_scores,\n","        \"Final_Score\": final_score\n","    }"],"metadata":{"id":"aMDsoc60R5jI","executionInfo":{"status":"ok","timestamp":1748106827937,"user_tz":-540,"elapsed":25,"user":{"displayName":"ê°•í™”ê²½","userId":"05664098802888959715"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# ì˜ˆì¸¡ ê²°ê³¼ ì˜ˆì‹œ (features_dfì—ì„œ ì •ë¦¬í•œ ìµœì¢… ê²°ê³¼ ìš”ì•½)\n","pred_df = pd.DataFrame({\n","    \"File\": [\"Validation1\", \"Validation2\", \"Validation3\", \"Validation4\", \"Validation5\", \"Validation6\"],\n","    \"RUL_Score(sec)\": [12023.895508, 71448.632812, 48502.957031, 73356.601562, 74936.945312, 29772.058594]\n","})\n","\n","# ì‹¤ì œ RUL ê°’ (ì˜ˆì‹œ, ì‹¤ì œ ê°’ìœ¼ë¡œ ë°”ê¿”ì•¼ í•¨)\n","true_rul_dict = {\n","    \"Validation1\": 12423,\n","    \"Validation2\": 70200,\n","    \"Validation3\": 48800,\n","    \"Validation4\": 72000,\n","    \"Validation5\": 75500,\n","    \"Validation6\": 29500,\n","}\n","\n","# ì‹¤ì œ RUL ì¶”ê°€\n","pred_df[\"Actual_RUL\"] = pred_df[\"File\"].map(true_rul_dict)\n","\n","# ì˜¤ì°¨ ë° ì •í™•ë„ ì ìˆ˜ ê³„ì‚°\n","pred_df[\"Error(%)\"] = calculate_error(pred_df[\"Actual_RUL\"], pred_df[\"RUL_Score(sec)\"])\n","pred_df[\"Accuracy_Score\"] = calculate_accuracy_score(pred_df[\"Error(%)\"])\n","\n","# ìµœì¢… í‰ê·  ì ìˆ˜ ê³„ì‚°\n","final_score = calculate_final_score(pred_df[\"Accuracy_Score\"])\n","\n","# ê²°ê³¼ ì¶œë ¥\n","print(pred_df)\n","print(\"\\nğŸ“Š Final Accuracy Score:\", round(final_score, 4))\n"],"metadata":{"id":"w_pLla6ESWFo"},"execution_count":null,"outputs":[]}]}